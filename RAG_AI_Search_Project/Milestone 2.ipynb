{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Mini Project\n",
    "## Milestone #2:\n",
    "This notebook uses the embedding code to create embeddings from the text chunks generated and save in Pickle file from Milestone #1.\n",
    "\n",
    "- Create a Python dictionary as a Vector database using the embedding vector as keys (note: convert list of embeddings to a tuple) and the text as the value\n",
    "- Experiment with some queries and use cosine similarity to get the most similar text from your vector database.\n",
    "- If the results are not satisfactory, you may want to refactor your code by:\n",
    "1. changing the embedding technique\n",
    "2. modifying the chunking technique from Milestone #1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 fixed-size chunks and 5 semantic chunks.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the chunks from the pickle file\n",
    "with open(\"chunks.pkl\", \"rb\") as f:\n",
    "    chunk_data = pickle.load(f)\n",
    "\n",
    "# Extract fixed-size and semantic chunks\n",
    "fixed_chunks = chunk_data.get(\"fixed_chunks\", [])\n",
    "semantic_chunks = chunk_data.get(\"semantic_chunks\", [])\n",
    "\n",
    "print(f\"Loaded {len(fixed_chunks)} fixed-size chunks and {len(semantic_chunks)} semantic chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 fixed-size embeddings and 5 semantic embeddings.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the same embedding model from Assignment A1\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings for fixed-size chunks\n",
    "fixed_embeddings = [model.encode(chunk) for chunk in fixed_chunks]\n",
    "\n",
    "# Generate embeddings for semantic chunks\n",
    "semantic_embeddings = [model.encode(chunk) for chunk in semantic_chunks]\n",
    "\n",
    "print(f\"Generated {len(fixed_embeddings)} fixed-size embeddings and {len(semantic_embeddings)} semantic embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database created with 5 fixed-size chunks and 5 semantic chunks.\n"
     ]
    }
   ],
   "source": [
    "# Convert embeddings to tuples (as required) and create a dictionary\n",
    "vector_db_fixed = {tuple(embedding): text for embedding, text in zip(fixed_embeddings, fixed_chunks)}\n",
    "vector_db_semantic = {tuple(embedding): text for embedding, text in zip(semantic_embeddings, semantic_chunks)}\n",
    "\n",
    "print(f\"Vector database created with {len(vector_db_fixed)} fixed-size chunks and {len(vector_db_semantic)} semantic chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Match:\n",
      "Agentic AI refers to artificial intelligence systems that exhibit autonomous decision-making, adaptability, and goal-directed behavior. Unlike traditional AI, which primarily follows predefined rules or relies on statistical pattern recognition, agentic AI is characterized by its ability to plan, reason, and take initiative in dynamic environments. This type of AI is particularly relevant for applications that require independent problem-solving, such as robotics, autonomous agents, and strategic decision-making systems.\n",
      "\n",
      "Similarity Score: 0.7948917746543884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def retrieve_similar_text(query, vector_db):\n",
    "    \"\"\"Find the most similar text chunk using cosine similarity.\"\"\"\n",
    "    \n",
    "    # Encode the query into an embedding\n",
    "    query_embedding = model.encode(query).reshape(1, -1)\n",
    "    \n",
    "    # Convert stored embeddings back to arrays for comparison\n",
    "    stored_embeddings = np.array([list(key) for key in vector_db.keys()])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_embedding, stored_embeddings)[0]\n",
    "    \n",
    "    # Find the most similar chunk\n",
    "    best_match_idx = np.argmax(similarities)\n",
    "    best_match_text = list(vector_db.values())[best_match_idx]\n",
    "    \n",
    "    return best_match_text, similarities[best_match_idx]\n",
    "\n",
    "# Example Query\n",
    "query = \"How does Agentic AI work?\"\n",
    "best_text, similarity_score = retrieve_similar_text(query, vector_db_semantic)\n",
    "\n",
    "print(f\"Best Match:\\n{best_text}\\n\\nSimilarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database saved as vector_db.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the vector database in a pickle file\n",
    "with open(\"vector_db.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"fixed\": vector_db_fixed, \"semantic\": vector_db_semantic}, f)\n",
    "\n",
    "print(\"Vector database saved as vector_db.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
